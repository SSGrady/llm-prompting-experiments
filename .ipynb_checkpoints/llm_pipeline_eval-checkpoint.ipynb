{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication\n",
    "Loads variables from `.env`:\n",
    "- `LLM_API_KEY`: **REQUIRED** Open Router API Key (other LLM providers are valid if the BASE_URL matches...)\n",
    "- `LLM_BASE_URL`: Defaults to `https://openrouter.ai/api/v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM API Key: sk-or-v1-...\n",
      "LLM Base URL: https://openrouter.ai/api/v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from textwrap import shorten\n",
    "from dotenv import load_dotenv\n",
    "from master_agent.llm import LlmClient, SubtasksGenerator\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_api_key = os.getenv('LLM_API_KEY')\n",
    "assert llm_api_key != None\n",
    "llm_base_url = os.getenv('LLM_BASE_URL', 'https://openrouter.ai/api/v1')\n",
    "\n",
    "print(f\"LLM API Key: {shorten(llm_api_key, width=25, placeholder='...')}\")\n",
    "print(f\"LLM Base URL: {llm_base_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Testing Dataset\n",
    "## Parameters:\n",
    "- **COLOR_NAMES**: These are the Object Colors provided from the Minigrid constants\n",
    "- **BATCH_SIZES**: Batches represent the number of trials (example envs) to be tested (starting small, scaling up based on success rate)\n",
    "- **MAX_OBJECTS**: The maximum number of object pairs generated from the environment\n",
    "- **MIN_OBJECTS**: The miniumum number of object pairs generated from the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_NAMES = sorted([\"red\", \"green\", \"blue\", \"purple\", \"yellow\"])\n",
    "BATCH_SIZES = [20, 50, 75, 100]\n",
    "MAX_OBJECTS = 3\n",
    "MIN_OBJECTS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Testing Dataset:\n",
      "           0           1          2           3          4           5\n",
      "0     KeyRed     DoorRed     KeyRed     DoorRed  KeyYellow  DoorYellow\n",
      "1   KeyGreen   DoorGreen    KeyBlue    DoorBlue    KeyBlue    DoorBlue\n",
      "2  KeyPurple  DoorPurple  KeyYellow  DoorYellow     KeyRed     DoorRed\n",
      "3   KeyGreen   DoorGreen    KeyBlue    DoorBlue       None        None\n",
      "4  KeyPurple  DoorPurple       None        None       None        None\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def generate_random_objects(num_objects: int) -> list[str]:\n",
    "    objects = []\n",
    "    for _ in range(num_objects):\n",
    "        color = random.choice(COLOR_NAMES).capitalize()\n",
    "        objects.append(f\"Key{color}\")\n",
    "        objects.append(f\"Door{color}\")\n",
    "    return objects\n",
    "# Generate a dataset of a specified batch size\n",
    "def generate_dataset(batch_size: int) -> pd.DataFrame:\n",
    "    data_set = [generate_random_objects(random.randint(MIN_OBJECTS, MAX_OBJECTS)) for _ in range(batch_size)]\n",
    "    return pd.DataFrame(data_set)\n",
    "\n",
    "df = pd.DataFrame([generate_random_objects(random.randint(MIN_OBJECTS, MAX_OBJECTS)) for i in range(BATCH_SIZES[0])])\n",
    "print(\"Generated Testing Dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test\n",
    "## Parameters\n",
    "- **RUN_PARALLEL**: Runs the model tests for each model in **AVAILABLE_MODELS** in parallel\n",
    "- **AVAILABLE_MODELS**: The models to be tested\n",
    "## Outputs\n",
    "- Graph #1: Compares model's success rates\n",
    "- Graph #2: Compares model's response times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_PARALLEL = True\n",
    "AVAILABLE_MODELS = [\n",
    "    \"openai/gpt-4o\",\n",
    "    \"anthropic/claude-3.5-sonnet\",\n",
    "    \"google/gemini-2.0-flash-001\",\n",
    "]\n",
    "# 95% accuracy target\n",
    "TARGET_ACCURACY = 95.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing with batch size: 20 ===\n",
      "\n",
      "2025-02-25 07:01:41 | [google/gemini-2.0-flash-001] iteration #1 Passed | Current success rate: 100.00% | Current avg duration: 2.19s\n",
      "2025-02-25 07:01:41 | [anthropic/claude-3.5-sonnet] iteration #1 Passed | Current success rate: 100.00% | Current avg duration: 4.09s\n",
      "2025-02-25 07:01:43 | [google/gemini-2.0-flash-001] iteration #2 Passed | Current success rate: 100.00% | Current avg duration: 2.33s\n",
      "2025-02-25 07:01:41 | [openai/gpt-4o] iteration #1 Passed | Current success rate: 100.00% | Current avg duration: 5.24s\n",
      "2025-02-25 07:01:46 | [google/gemini-2.0-flash-001] iteration #3 Passed | Current success rate: 100.00% | Current avg duration: 2.10s\n",
      "2025-02-25 07:01:47 | [google/gemini-2.0-flash-001] iteration #4 Passed | Current success rate: 100.00% | Current avg duration: 2.03s\n",
      "2025-02-25 07:01:45 | [anthropic/claude-3.5-sonnet] iteration #2 Passed | Current success rate: 100.00% | Current avg duration: 4.23s\n",
      "2025-02-25 07:01:49 | [google/gemini-2.0-flash-001] iteration #5 Passed | Current success rate: 100.00% | Current avg duration: 1.96s\n",
      "2025-02-25 07:01:46 | [openai/gpt-4o] iteration #2 Passed | Current success rate: 100.00% | Current avg duration: 4.94s\n",
      "2025-02-25 07:01:51 | [google/gemini-2.0-flash-001] iteration #6 Passed | Current success rate: 100.00% | Current avg duration: 2.03s\n",
      "2025-02-25 07:01:50 | [anthropic/claude-3.5-sonnet] iteration #3 Passed | Current success rate: 100.00% | Current avg duration: 4.07s\n",
      "2025-02-25 07:01:51 | [openai/gpt-4o] iteration #3 Passed | Current success rate: 100.00% | Current avg duration: 4.47s\n",
      "2025-02-25 07:01:53 | [google/gemini-2.0-flash-001] iteration #7 Passed | Current success rate: 100.00% | Current avg duration: 1.99s\n",
      "2025-02-25 07:01:53 | [anthropic/claude-3.5-sonnet] iteration #4 Passed | Current success rate: 100.00% | Current avg duration: 3.86s\n",
      "2025-02-25 07:01:55 | [google/gemini-2.0-flash-001] iteration #8 Passed | Current success rate: 100.00% | Current avg duration: 1.99s\n",
      "2025-02-25 07:01:55 | [openai/gpt-4o] iteration #4 Passed | Current success rate: 100.00% | Current avg duration: 4.02s\n",
      "2025-02-25 07:01:57 | [openai/gpt-4o] iteration #5 Passed | Current success rate: 100.00% | Current avg duration: 3.95s\n",
      "2025-02-25 07:01:57 | [anthropic/claude-3.5-sonnet] iteration #5 Passed | Current success rate: 100.00% | Current avg duration: 4.04s\n",
      "2025-02-25 07:01:57 | [google/gemini-2.0-flash-001] iteration #9 Passed | Current success rate: 100.00% | Current avg duration: 2.30s\n",
      "2025-02-25 07:02:01 | [openai/gpt-4o] iteration #6 Passed | Current success rate: 100.00% | Current avg duration: 3.65s\n",
      "2025-02-25 07:02:02 | [google/gemini-2.0-flash-001] iteration #10 Passed | Current success rate: 100.00% | Current avg duration: 2.25s\n",
      "2025-02-25 07:02:01 | [anthropic/claude-3.5-sonnet] iteration #6 Passed2025-02-25 07:02:04 | [google/gemini-2.0-flash-001] iteration #11  | Current success rate: 100.00% | Current avg duration: 4.05sPassed\n",
      " | Current success rate: 100.00% | Current avg duration: 2.21s\n",
      "2025-02-25 07:02:03 | [openai/gpt-4o] iteration #7 Passed | Current success rate: 100.00% | Current avg duration: 3.52s\n",
      "2025-02-25 07:02:06 | [openai/gpt-4o] iteration #8 Passed | Current success rate: 100.00% | Current avg duration: 3.42s\n",
      "2025-02-25 07:02:05 | [anthropic/claude-3.5-sonnet] iteration #7 Passed | Current success rate: 100.00% | Current avg duration: 4.04s\n",
      "2025-02-25 07:02:09 | [openai/gpt-4o] iteration #9 Passed | Current success rate: 100.00% | Current avg duration: 3.32s\n",
      "2025-02-25 07:02:09 | [anthropic/claude-3.5-sonnet] iteration #8 Passed | Current success rate: 100.00% | Current avg duration: 4.07s\n",
      "2025-02-25 07:02:05 | [google/gemini-2.0-flash-001] iteration #12 Passed | Current success rate: 100.00% | Current avg duration: 2.73s\n",
      "2025-02-25 07:02:11 | [openai/gpt-4o] iteration #10 Passed | Current success rate: 100.00% | Current avg duration: 3.41s\n",
      "2025-02-25 07:02:14 | [google/gemini-2.0-flash-001] iteration #13 Passed | Current success rate: 100.00% | Current avg duration: 2.67s\n",
      "2025-02-25 07:02:14 | [anthropic/claude-3.5-sonnet] iteration #9 Passed | Current success rate: 100.00% | Current avg duration: 4.03s\n",
      "2025-02-25 07:02:16 | [google/gemini-2.0-flash-001] iteration #14 Passed | Current success rate: 100.00% | Current avg duration: 2.60s\n",
      "2025-02-25 07:02:15 | [openai/gpt-4o] iteration #11 Passed | Current success rate: 100.00% | Current avg duration: 3.32s\n",
      "2025-02-25 07:02:18 | [google/gemini-2.0-flash-001] iteration #15 Passed | Current success rate: 100.00% | Current avg duration: 2.57s\n",
      "2025-02-25 07:02:17 | [anthropic/claude-3.5-sonnet] iteration #10 Passed | Current success rate: 100.00% | Current avg duration: 4.00s\n",
      "2025-02-25 07:02:20 | [google/gemini-2.0-flash-001] iteration #16 Passed | Current success rate: 100.00% | Current avg duration: 2.51s\n",
      "2025-02-25 07:02:18 | [openai/gpt-4o] iteration #12 Passed | Current success rate: 100.00% | Current avg duration: 3.44s\n",
      "2025-02-25 07:02:21 | [google/gemini-2.0-flash-001] iteration #17 Passed | Current success rate: 100.00% | Current avg duration: 2.50s\n",
      "2025-02-25 07:02:21 | [anthropic/claude-3.5-sonnet] iteration #11 Passed | Current success rate: 100.00% | Current avg duration: 3.96s\n",
      "2025-02-25 07:02:24 | [google/gemini-2.0-flash-001] iteration #18 Passed | Current success rate: 100.00% | Current avg duration: 2.48s\n",
      "2025-02-25 07:02:22 | [openai/gpt-4o] iteration #13 Passed | Current success rate: 100.00% | Current avg duration: 3.50s\n",
      "2025-02-25 07:02:26 | [google/gemini-2.0-flash-001] iteration #19 Passed | Current success rate: 100.00% | Current avg duration: 2.45s\n",
      "2025-02-25 07:02:25 | [anthropic/claude-3.5-sonnet] iteration #12 Passed | Current success rate: 100.00% | Current avg duration: 3.98s\n",
      "2025-02-25 07:02:27 | [openai/gpt-4o] iteration #14 Passed | Current success rate: 100.00% | Current avg duration: 3.42s\n",
      "2025-02-25 07:02:28 | [google/gemini-2.0-flash-001] iteration #20 Passed | Current success rate: 100.00% | Current avg duration: 2.40s\n",
      "2025-02-25 07:02:29 | [anthropic/claude-3.5-sonnet] iteration #13 Passed | Current success rate: 100.00% | Current avg duration: 3.98s\n",
      "2025-02-25 07:02:29 | [openai/gpt-4o] iteration #15 Passed | Current success rate: 100.00% | Current avg duration: 3.51s\n",
      "2025-02-25 07:02:34 | [openai/gpt-4o] iteration #16 Passed | Current success rate: 100.00% | Current avg duration: 3.43s\n",
      "2025-02-25 07:02:33 | [anthropic/claude-3.5-sonnet] iteration #14 Passed | Current success rate: 100.00% | Current avg duration: 3.94s\n",
      "2025-02-25 07:02:36 | [anthropic/claude-3.5-sonnet] iteration #15 Passed | Current success rate: 100.00% | Current avg duration: 3.95s\n",
      "2025-02-25 07:02:36 | [openai/gpt-4o] iteration #17 Passed | Current success rate: 100.00% | Current avg duration: 3.51s\n",
      "2025-02-25 07:02:40 | [anthropic/claude-3.5-sonnet] iteration #16 Passed | Current success rate: 100.00% | Current avg duration: 3.95s\n",
      "2025-02-25 07:02:41 | [openai/gpt-4o] iteration #18 Passed | Current success rate: 100.00% | Current avg duration: 3.60s\n",
      "2025-02-25 07:02:44 | [anthropic/claude-3.5-sonnet] iteration #17 Passed | Current success rate: 100.00% | Current avg duration: 3.96s\n",
      "2025-02-25 07:02:46 | [openai/gpt-4o] iteration #19 Passed | Current success rate: 100.00% | Current avg duration: 3.61s\n",
      "2025-02-25 07:02:50 | [openai/gpt-4o] iteration #20 Passed | Current success rate: 100.00% | Current avg duration: 3.53s\n",
      "2025-02-25 07:02:49 | [anthropic/claude-3.5-sonnet] iteration #18 Passed | Current success rate: 100.00% | Current avg duration: 4.24s\n",
      "2025-02-25 07:02:57 | [anthropic/claude-3.5-sonnet] iteration #19 Passed | Current success rate: 100.00% | Current avg duration: 4.47s\n",
      "2025-02-25 07:03:06 | [anthropic/claude-3.5-sonnet] iteration #20 Passed | Current success rate: 100.00% | Current avg duration: 4.44s\n",
      "\n",
      "Summary for Batch Size 20:\n",
      "google/gemini-2.0-flash-001: 20/20 passed (100.00%), Avg test duration: 2.40s\n",
      "openai/gpt-4o: 20/20 passed (100.00%), Avg test duration: 3.53s\n",
      "anthropic/claude-3.5-sonnet: 20/20 passed (100.00%), Avg test duration: 4.44s\n",
      "\n",
      "=== Testing with batch size: 50 ===\n",
      "\n",
      "2025-02-25 07:03:10 | [google/gemini-2.0-flash-001] iteration #1 Passed | Current success rate: 100.00% | Current avg duration: 2.29s\n",
      "2025-02-25 07:03:12 | [google/gemini-2.0-flash-001] iteration #2 Passed | Current success rate: 100.00% | Current avg duration: 1.96s\n",
      "2025-02-25 07:03:10 | [anthropic/claude-3.5-sonnet] iteration #1 Passed | Current success rate: 100.00% | Current avg duration: 3.97s\n",
      "2025-02-25 07:03:10 | [openai/gpt-4o] iteration #1 Passed | Current success rate: 100.00% | Current avg duration: 4.44s\n",
      "2025-02-25 07:03:15 | [openai/gpt-4o] iteration #2 Passed | Current success rate: 100.00% | Current avg duration: 3.13s\n",
      "2025-02-25 07:03:14 | [anthropic/claude-3.5-sonnet] iteration #2 Passed | Current success rate: 100.00% | Current avg duration: 3.98s\n",
      "2025-02-25 07:03:16 | [openai/gpt-4o] iteration #3 Passed | Current success rate: 100.00% | Current avg duration: 3.07s\n",
      "2025-02-25 07:03:18 | [anthropic/claude-3.5-sonnet] iteration #3 Passed | Current success rate: 100.00% | Current avg duration: 3.77s\n",
      "2025-02-25 07:03:19 | [openai/gpt-4o] iteration #4 Passed | Current success rate: 100.00% | Current avg duration: 3.19s\n",
      "2025-02-25 07:03:21 | [anthropic/claude-3.5-sonnet] iteration #4 Passed | Current success rate: 100.00% | Current avg duration: 3.76s\n",
      "2025-02-25 07:03:23 | [openai/gpt-4o] iteration #5 Passed | Current success rate: 100.00% | Current avg duration: 3.31s\n",
      "2025-02-25 07:03:25 | [anthropic/claude-3.5-sonnet] iteration #5 Passed | Current success rate: 100.00% | Current avg duration: 3.79s\n",
      "2025-02-25 07:03:27 | [openai/gpt-4o] iteration #6 Passed | Current success rate: 100.00% | Current avg duration: 3.74s\n",
      "2025-02-25 07:03:29 | [anthropic/claude-3.5-sonnet] iteration #6 Passed | Current success rate: 100.00% | Current avg duration: 3.81s\n",
      "2025-02-25 07:03:33 | [openai/gpt-4o] iteration #7 Passed | Current success rate: 100.00% | Current avg duration: 3.52s\n",
      "2025-02-25 07:03:14 | [google/gemini-2.0-flash-001] iteration #3 Passed | Current success rate: 100.00% | Current avg duration: 8.53s\n",
      "2025-02-25 07:03:35 | [openai/gpt-4o] iteration #8 Passed | Current success rate: 100.00% | Current avg duration: 3.33s\n",
      "2025-02-25 07:03:36 | [google/gemini-2.0-flash-001] iteration #4 Passed | Current success rate: 100.00% | Current avg duration: 6.74s\n",
      "2025-02-25 07:03:37 | [google/gemini-2.0-flash-001] iteration #5 Passed | Current success rate: 100.00% | Current avg duration: 5.73s\n",
      "2025-02-25 07:03:37 | [openai/gpt-4o] iteration #9 Passed | Current success rate: 100.00% | Current avg duration: 3.29s\n",
      "2025-02-25 07:03:39 | [google/gemini-2.0-flash-001] iteration #6 Passed | Current success rate: 100.00% | Current avg duration: 5.11s\n",
      "2025-02-25 07:03:40 | [openai/gpt-4o] iteration #10 Passed | Current success rate: 100.00% | Current avg duration: 3.14s\n",
      "2025-02-25 07:03:41 | [google/gemini-2.0-flash-001] iteration #7 Passed | Current success rate: 100.00% | Current avg duration: 4.57s\n",
      "2025-02-25 07:03:33 | [anthropic/claude-3.5-sonnet] iteration #7 Passed | Current success rate: 100.00% | Current avg duration: 4.71s\n",
      "2025-02-25 07:03:42 | [google/gemini-2.0-flash-001] iteration #8 Passed | Current success rate: 100.00% | Current avg duration: 4.18s\n",
      "2025-02-25 07:03:41 | [openai/gpt-4o] iteration #11 Passed | Current success rate: 100.00% | Current avg duration: 3.14s\n",
      "2025-02-25 07:03:44 | [google/gemini-2.0-flash-001] iteration #9 Passed | Current success rate: 100.00% | Current avg duration: 3.94s\n",
      "2025-02-25 07:03:43 | [anthropic/claude-3.5-sonnet] iteration #8 Passed | Current success rate: 100.00% | Current avg duration: 4.46s\n",
      "2025-02-25 07:03:46 | [google/gemini-2.0-flash-001] iteration #10 Passed | Current success rate: 100.00% | Current avg duration: 3.69s\n",
      "2025-02-25 07:03:45 | [openai/gpt-4o] iteration #12 Passed | Current success rate: 100.00% | Current avg duration: 3.17s\n",
      "2025-02-25 07:03:46 | [anthropic/claude-3.5-sonnet] iteration #9 Passed | Current success rate: 100.00% | Current avg duration: 4.31s\n",
      "2025-02-25 07:03:48 | [openai/gpt-4o] iteration #13 Passed | Current success rate: 100.00% | Current avg duration: 3.16s\n",
      "2025-02-25 07:03:49 | [anthropic/claude-3.5-sonnet] iteration #10 Passed | Current success rate: 100.00% | Current avg duration: 4.15s\n",
      "2025-02-25 07:03:51 | [openai/gpt-4o] iteration #14 Passed | Current success rate: 100.00% | Current avg duration: 3.19s\n",
      "2025-02-25 07:03:52 | [anthropic/claude-3.5-sonnet] iteration #11 Passed | Current success rate: 100.00% | Current avg duration: 4.06s\n",
      "2025-02-25 07:03:55 | [openai/gpt-4o] iteration #15 Passed | Current success rate: 100.00% | Current avg duration: 3.20s\n",
      "2025-02-25 07:03:55 | [anthropic/claude-3.5-sonnet] iteration #12 Passed | Current success rate: 100.00% | Current avg duration: 4.00s\n",
      "2025-02-25 07:03:58 | [openai/gpt-4o] iteration #16 Passed | Current success rate: 100.00% | Current avg duration: 3.15s\n",
      "2025-02-25 07:03:47 | [google/gemini-2.0-flash-001] iteration #11 Passed | Current success rate: 100.00% | Current avg duration: 4.68s\n",
      "2025-02-25 07:03:58 | [anthropic/claude-3.5-sonnet] iteration #13 Passed | Current success rate: 100.00% | Current avg duration: 4.06s\n",
      "2025-02-25 07:04:02 | [google/gemini-2.0-flash-001] iteration #12 Passed | Current success rate: 100.00% | Current avg duration: 4.42s\n",
      "2025-02-25 07:04:03 | [google/gemini-2.0-flash-001] iteration #13 Passed | Current success rate: 100.00% | Current avg duration: 4.19s\n",
      "2025-02-25 07:04:01 | [openai/gpt-4o] iteration #17 Passed | Current success rate: 100.00% | Current avg duration: 3.27s\n",
      "2025-02-25 07:04:05 | [google/gemini-2.0-flash-001] iteration #14 Passed | Current success rate: 100.00% | Current avg duration: 4.07s\n",
      "2025-02-25 07:04:06 | [openai/gpt-4o] iteration #18 Passed | Current success rate: 100.00% | Current avg duration: 3.20s\n",
      "2025-02-25 07:04:07 | [google/gemini-2.0-flash-001] iteration #15 Passed | Current success rate: 100.00% | Current avg duration: 3.89s\n",
      "2025-02-25 07:04:03 | [anthropic/claude-3.5-sonnet] iteration #14 Passed | Current success rate: 100.00% | Current avg duration: 4.17s\n",
      "2025-02-25 07:04:08 | [google/gemini-2.0-flash-001] iteration #16 Passed | Current success rate: 100.00% | Current avg duration: 3.73s\n",
      "2025-02-25 07:04:10 | [google/gemini-2.0-flash-001] iteration #17 Passed | Current success rate: 100.00% | Current avg duration: 3.61s\n",
      "2025-02-25 07:04:09 | [anthropic/claude-3.5-sonnet] iteration #15 Passed | Current success rate: 100.00% | Current avg duration: 4.10s\n",
      "2025-02-25 07:04:12 | [google/gemini-2.0-flash-001] iteration #18 Passed | Current success rate: 100.00% | Current avg duration: 3.51s\n",
      "2025-02-25 07:04:08 | [openai/gpt-4o] iteration #19 Passed | Current success rate: 100.00% | Current avg duration: 3.35s\n",
      "2025-02-25 07:04:13 | [google/gemini-2.0-flash-001] iteration #19 Passed | Current success rate: 100.00% | Current avg duration: 3.42s\n",
      "2025-02-25 07:04:12 | [anthropic/claude-3.5-sonnet] iteration #16 Passed | Current success rate: 100.00% | Current avg duration: 4.09s\n",
      "2025-02-25 07:04:14 | [openai/gpt-4o] iteration #20 Passed | Current success rate: 100.00% | Current avg duration: 3.34s\n",
      "2025-02-25 07:04:15 | [google/gemini-2.0-flash-001] iteration #20 Passed | Current success rate: 100.00% | Current avg duration: 3.35s\n",
      "2025-02-25 07:04:17 | [google/gemini-2.0-flash-001] iteration #21 Passed | Current success rate: 100.00% | Current avg duration: 3.28s\n",
      "2025-02-25 07:04:15 | [anthropic/claude-3.5-sonnet] iteration #17 Passed | Current success rate: 100.00% | Current avg duration: 4.08s\n",
      "2025-02-25 07:04:17 | [openai/gpt-4o] iteration #21 Passed | Current success rate: 100.00% | Current avg duration: 3.34s\n",
      "2025-02-25 07:04:19 | [google/gemini-2.0-flash-001] iteration #22 Passed | Current success rate: 100.00% | Current avg duration: 3.26s\n",
      "2025-02-25 07:04:20 | [anthropic/claude-3.5-sonnet] iteration #18 Passed | Current success rate: 100.00% | Current avg duration: 4.05s\n",
      "2025-02-25 07:04:22 | [google/gemini-2.0-flash-001] iteration #23 Passed | Current success rate: 100.00% | Current avg duration: 3.18s\n",
      "2025-02-25 07:04:23 | [google/gemini-2.0-flash-001] iteration #24 Passed | Current success rate: 100.00% | Current avg duration: 3.10s\n",
      "2025-02-25 07:04:20 | [openai/gpt-4o] iteration #22 Passed | Current success rate: 100.00% | Current avg duration: 3.44s\n",
      "2025-02-25 07:04:25 | [google/gemini-2.0-flash-001] iteration #25 Passed | Current success rate: 100.00% | Current avg duration: 3.04s\n",
      "2025-02-25 07:04:23 | [anthropic/claude-3.5-sonnet] iteration #19 Passed | Current success rate: 100.00% | Current avg duration: 4.07s\n",
      "2025-02-25 07:04:26 | [google/gemini-2.0-flash-001] iteration #26 Passed | Current success rate: 100.00% | Current avg duration: 2.99s\n",
      "2025-02-25 07:04:26 | [openai/gpt-4o] iteration #23 Passed | Current success rate: 100.00% | Current avg duration: 3.41s\n",
      "2025-02-25 07:04:28 | [google/gemini-2.0-flash-001] iteration #27 Passed | Current success rate: 100.00% | Current avg duration: 2.96s\n",
      "2025-02-25 07:04:27 | [anthropic/claude-3.5-sonnet] iteration #20 Passed | Current success rate: 100.00% | Current avg duration: 4.06s\n",
      "2025-02-25 07:04:30 | [google/gemini-2.0-flash-001] iteration #28 Passed | Current success rate: 100.00% | Current avg duration: 2.90s\n",
      "2025-02-25 07:04:28 | [openai/gpt-4o] iteration #24 Passed | Current success rate: 100.00% | Current avg duration: 3.44s\n",
      "2025-02-25 07:04:31 | [google/gemini-2.0-flash-001] iteration #29 Passed | Current success rate: 100.00% | Current avg duration: 2.85s\n",
      "2025-02-25 07:04:33 | [google/gemini-2.0-flash-001] iteration #30 Passed | Current success rate: 100.00% | Current avg duration: 2.81s\n",
      "2025-02-25 07:04:33 | [openai/gpt-4o] iteration #25 Passed | Current success rate: 100.00% | Current avg duration: 3.39s\n",
      "2025-02-25 07:04:31 | [anthropic/claude-3.5-sonnet] iteration #21 Passed | Current success rate: 100.00% | Current avg duration: 4.05s\n",
      "2025-02-25 07:04:34 | [google/gemini-2.0-flash-001] iteration #31 Passed | Current success rate: 100.00% | Current avg duration: 2.79s\n",
      "2025-02-25 07:04:35 | [openai/gpt-4o] iteration #26 Passed | Current success rate: 100.00% | Current avg duration: 3.36s\n",
      "2025-02-25 07:04:35 | [anthropic/claude-3.5-sonnet] iteration #22 Passed | Current success rate: 100.00% | Current avg duration: 4.01s\n",
      "2025-02-25 07:04:37 | [google/gemini-2.0-flash-001] iteration #32 Passed | Current success rate: 100.00% | Current avg duration: 2.77s\n",
      "2025-02-25 07:04:39 | [google/gemini-2.0-flash-001] iteration #33 Passed | Current success rate: 100.00% | Current avg duration: 2.73s\n",
      "2025-02-25 07:04:38 | [openai/gpt-4o] iteration #27 Passed | Current success rate: 100.00% | Current avg duration: 3.37s\n",
      "2025-02-25 07:04:40 | [google/gemini-2.0-flash-001] iteration #34 Passed | Current success rate: 100.00% | Current avg duration: 2.71s\n",
      "2025-02-25 07:04:38 | [anthropic/claude-3.5-sonnet] iteration #23 Passed | Current success rate: 100.00% | Current avg duration: 4.00s\n",
      "2025-02-25 07:04:41 | [openai/gpt-4o] iteration #28 Passed | Current success rate: 100.00% | Current avg duration: 3.31s\n",
      "2025-02-25 07:04:42 | [google/gemini-2.0-flash-001] iteration #35 Passed | Current success rate: 100.00% | Current avg duration: 2.69s\n",
      "2025-02-25 07:04:43 | [openai/gpt-4o] iteration #29 Passed | Current success rate: 100.00% | Current avg duration: 3.28s\n",
      "2025-02-25 07:04:44 | [google/gemini-2.0-flash-001] iteration #36 Passed | Current success rate: 100.00% | Current avg duration: 2.66s\n",
      "2025-02-25 07:04:45 | [openai/gpt-4o] iteration #30 Passed | Current success rate: 100.00% | Current avg duration: 3.23s\n",
      "2025-02-25 07:04:46 | [google/gemini-2.0-flash-001] iteration #37 Passed | Current success rate: 100.00% | Current avg duration: 2.65s\n",
      "2025-02-25 07:04:48 | [google/gemini-2.0-flash-001] iteration #38 Passed | Current success rate: 100.00% | Current avg duration: 2.64s\n",
      "2025-02-25 07:04:42 | [anthropic/claude-3.5-sonnet] iteration #24 Passed | Current success rate: 100.00% | Current avg duration: 4.19s\n",
      "2025-02-25 07:04:47 | [openai/gpt-4o] iteration #31 Passed | Current success rate: 100.00% | Current avg duration: 3.26s\n",
      "2025-02-25 07:04:50 | [google/gemini-2.0-flash-001] iteration #39 Passed | Current success rate: 100.00% | Current avg duration: 2.61s\n",
      "2025-02-25 07:04:52 | [google/gemini-2.0-flash-001] iteration #40 Passed | Current success rate: 100.00% | Current avg duration: 2.59s\n",
      "2025-02-25 07:04:51 | [anthropic/claude-3.5-sonnet] iteration #25 Passed | Current success rate: 100.00% | Current avg duration: 4.16s\n",
      "2025-02-25 07:04:51 | [openai/gpt-4o] iteration #32 Passed | Current success rate: 100.00% | Current avg duration: 3.26s\n",
      "2025-02-25 07:04:54 | [google/gemini-2.0-flash-001] iteration #41 Passed | Current success rate: 100.00% | Current avg duration: 2.57s\n",
      "2025-02-25 07:04:56 | [google/gemini-2.0-flash-001] iteration #42 Passed | Current success rate: 100.00% | Current avg duration: 2.55s\n",
      "2025-02-25 07:04:54 | [anthropic/claude-3.5-sonnet] iteration #26 Passed | Current success rate: 100.00% | Current avg duration: 4.16s\n",
      "2025-02-25 07:04:54 | [openai/gpt-4o] iteration #33 Passed | Current success rate: 100.00% | Current avg duration: 3.28s\n",
      "2025-02-25 07:04:57 | [google/gemini-2.0-flash-001] iteration #43 Passed | Current success rate: 100.00% | Current avg duration: 2.53s\n",
      "2025-02-25 07:04:59 | [google/gemini-2.0-flash-001] iteration #44 Passed | Current success rate: 100.00% | Current avg duration: 2.51s\n",
      "2025-02-25 07:04:58 | [openai/gpt-4o] iteration #34 Passed | Current success rate: 100.00% | Current avg duration: 3.25s\n",
      "2025-02-25 07:04:58 | [anthropic/claude-3.5-sonnet] iteration #27 Passed | Current success rate: 100.00% | Current avg duration: 4.15s\n",
      "2025-02-25 07:05:01 | [google/gemini-2.0-flash-001] iteration #45 Passed | Current success rate: 100.00% | Current avg duration: 2.49s\n",
      "2025-02-25 07:05:02 | [google/gemini-2.0-flash-001] iteration #46 Passed | Current success rate: 100.00% | Current avg duration: 2.47s\n",
      "2025-02-25 07:05:02 | [anthropic/claude-3.5-sonnet] iteration #28 Passed | Current success rate: 100.00% | Current avg duration: 4.11s\n",
      "2025-02-25 07:05:04 | [google/gemini-2.0-flash-001] iteration #47 Passed | Current success rate: 100.00% | Current avg duration: 2.45s\n",
      "2025-02-25 07:05:05 | [google/gemini-2.0-flash-001] iteration #48 Passed | Current success rate: 100.00% | Current avg duration: 2.43s\n",
      "2025-02-25 07:05:05 | [anthropic/claude-3.5-sonnet] iteration #29 Passed | Current success rate: 100.00% | Current avg duration: 4.09s\n",
      "2025-02-25 07:05:07 | [google/gemini-2.0-flash-001] iteration #49 Passed | Current success rate: 100.00% | Current avg duration: 2.42s\n",
      "2025-02-25 07:05:01 | [openai/gpt-4o] iteration #35 Passed | Current success rate: 100.00% | Current avg duration: 3.45s\n",
      "2025-02-25 07:05:09 | [google/gemini-2.0-flash-001] iteration #50 Passed | Current success rate: 100.00% | Current avg duration: 2.42s\n",
      "2025-02-25 07:05:09 | [anthropic/claude-3.5-sonnet] iteration #30 Passed | Current success rate: 100.00% | Current avg duration: 4.08s\n",
      "2025-02-25 07:05:11 | [openai/gpt-4o] iteration #36 Passed | Current success rate: 100.00% | Current avg duration: 3.46s\n",
      "2025-02-25 07:05:13 | [anthropic/claude-3.5-sonnet] iteration #31 Passed | Current success rate: 100.00% | Current avg duration: 4.07s\n",
      "2025-02-25 07:05:15 | [openai/gpt-4o] iteration #37 Passed | Current success rate: 100.00% | Current avg duration: 3.41s\n",
      "2025-02-25 07:05:16 | [openai/gpt-4o] iteration #38 Passed | Current success rate: 100.00% | Current avg duration: 3.41s\n",
      "2025-02-25 07:05:16 | [anthropic/claude-3.5-sonnet] iteration #32 Passed | Current success rate: 100.00% | Current avg duration: 4.07s\n",
      "2025-02-25 07:05:20 | [openai/gpt-4o] iteration #39 Passed | Current success rate: 100.00% | Current avg duration: 3.37s\n",
      "2025-02-25 07:05:22 | [openai/gpt-4o] iteration #40 Passed | Current success rate: 100.00% | Current avg duration: 3.33s\n",
      "2025-02-25 07:05:20 | [anthropic/claude-3.5-sonnet] iteration #33 Passed | Current success rate: 100.00% | Current avg duration: 4.05s\n",
      "2025-02-25 07:05:24 | [anthropic/claude-3.5-sonnet] iteration #34 Passed | Current success rate: 100.00% | Current avg duration: 4.04s\n",
      "2025-02-25 07:05:24 | [openai/gpt-4o] iteration #41 Passed | Current success rate: 100.00% | Current avg duration: 3.38s\n",
      "2025-02-25 07:05:28 | [anthropic/claude-3.5-sonnet] iteration #35 Passed | Current success rate: 100.00% | Current avg duration: 4.03s\n",
      "2025-02-25 07:05:29 | [openai/gpt-4o] iteration #42 Passed | Current success rate: 100.00% | Current avg duration: 3.45s\n",
      "2025-02-25 07:05:31 | [anthropic/claude-3.5-sonnet] iteration #36 Passed | Current success rate: 100.00% | Current avg duration: 4.03s\n",
      "2025-02-25 07:05:35 | [openai/gpt-4o] iteration #43 Passed | Current success rate: 100.00% | Current avg duration: 3.43s\n",
      "2025-02-25 07:05:35 | [anthropic/claude-3.5-sonnet] iteration #37 Passed | Current success rate: 100.00% | Current avg duration: 4.01s\n",
      "2025-02-25 07:05:38 | [openai/gpt-4o] iteration #44 Passed | Current success rate: 100.00% | Current avg duration: 3.46s\n",
      "2025-02-25 07:05:38 | [anthropic/claude-3.5-sonnet] iteration #38 Passed | Current success rate: 100.00% | Current avg duration: 4.02s\n",
      "2025-02-25 07:05:43 | [anthropic/claude-3.5-sonnet] iteration #39 Passed | Current success rate: 100.00% | Current avg duration: 4.00s\n",
      "2025-02-25 07:05:42 | [openai/gpt-4o] iteration #45 Passed | Current success rate: 100.00% | Current avg duration: 3.48s\n",
      "2025-02-25 07:05:47 | [openai/gpt-4o] iteration #46 Passed | Current success rate: 100.00% | Current avg duration: 3.48s\n",
      "2025-02-25 07:05:46 | [anthropic/claude-3.5-sonnet] iteration #40 Passed | Current success rate: 100.00% | Current avg duration: 4.00s\n",
      "2025-02-25 07:05:50 | [openai/gpt-4o] iteration #47 Passed | Current success rate: 100.00% | Current avg duration: 3.46s\n",
      "2025-02-25 07:05:50 | [anthropic/claude-3.5-sonnet] iteration #41 Passed | Current success rate: 100.00% | Current avg duration: 4.00s\n",
      "2025-02-25 07:05:53 | [openai/gpt-4o] iteration #48 Passed | Current success rate: 100.00% | Current avg duration: 3.49s\n",
      "2025-02-25 07:05:54 | [anthropic/claude-3.5-sonnet] iteration #42 Passed | Current success rate: 100.00% | Current avg duration: 3.99s\n",
      "2025-02-25 07:05:58 | [anthropic/claude-3.5-sonnet] iteration #43 Passed | Current success rate: 100.00% | Current avg duration: 3.99s\n",
      "2025-02-25 07:05:58 | [openai/gpt-4o] iteration #49 Passed | Current success rate: 100.00% | Current avg duration: 3.52s\n",
      "2025-02-25 07:06:02 | [anthropic/claude-3.5-sonnet] iteration #44 Passed | Current success rate: 100.00% | Current avg duration: 3.99s\n",
      "2025-02-25 07:06:03 | [openai/gpt-4o] iteration #50 Passed | Current success rate: 100.00% | Current avg duration: 3.56s\n",
      "2025-02-25 07:06:06 | [anthropic/claude-3.5-sonnet] iteration #45 Passed | Current success rate: 100.00% | Current avg duration: 4.00s\n",
      "2025-02-25 07:06:10 | [anthropic/claude-3.5-sonnet] iteration #46 Passed | Current success rate: 100.00% | Current avg duration: 4.01s\n",
      "2025-02-25 07:06:15 | [anthropic/claude-3.5-sonnet] iteration #47 Passed | Current success rate: 100.00% | Current avg duration: 3.99s\n",
      "2025-02-25 07:06:18 | [anthropic/claude-3.5-sonnet] iteration #48 Passed | Current success rate: 100.00% | Current avg duration: 4.00s\n",
      "2025-02-25 07:06:22 | [anthropic/claude-3.5-sonnet] iteration #49 Passed | Current success rate: 100.00% | Current avg duration: 4.81s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, objects_list, batch_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[43msubtasks_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_subtask_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     successes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Projects/UCF-SENIOR-DESIGN/local/llm-prompting-experiments/master_agent/llm/subtasks.py:45\u001b[0m, in \u001b[0;36mSubtasksGenerator.gen_subtask_paths\u001b[0;34m(self, objects, custom_prompt)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate valid paths from start to goal using provided objects.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    Exception: If LLM returns empty response or no paths\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m content \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a reasoning agent that generates paths from initial states to goal states in a grid-based environment. Each path is a sequence of symbolic states. Output JSON only.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_gen_subtasks_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content\u001b[38;5;241m.\u001b[39mstrip():\n",
      "File \u001b[0;32m~/Desktop/Projects/UCF-SENIOR-DESIGN/local/llm-prompting-experiments/master_agent/llm/client.py:57\u001b[0m, in \u001b[0;36mLlmClient.complete\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Complete a conversation given a list of message objects.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    The model's response text\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/resources/chat/completions.py:850\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    849\u001b[0m validate_response_format(response_format)\n\u001b[0;32m--> 850\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1280\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m )\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/keys', 'code': 403}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Run the progressive batch tests\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_progressive_batch_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Prepare data for visualization\u001b[39;00m\n\u001b[1;32m    117\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]))\n",
      "Cell \u001b[0;32mIn[5], line 91\u001b[0m, in \u001b[0;36mrun_progressive_batch_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m         future_to_model \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     87\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(test_model, model, objects_list, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m): model\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m AVAILABLE_MODELS\n\u001b[1;32m     89\u001b[0m         }\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(future_to_model):\n\u001b[0;32m---> 91\u001b[0m             result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m             batch_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[5], line 51\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, objects_list, batch_name)\u001b[0m\n\u001b[1;32m     49\u001b[0m     result_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     result_color \u001b[38;5;241m=\u001b[39m Fore\u001b[38;5;241m.\u001b[39mRED\n\u001b[0;32m---> 51\u001b[0m     failure_cases\u001b[38;5;241m.\u001b[39mappend((objects, \u001b[38;5;28mstr\u001b[39m(\u001b[43me\u001b[49m)))\n\u001b[1;32m     53\u001b[0m iteration_duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     54\u001b[0m durations\u001b[38;5;241m.\u001b[39mappend(iteration_duration)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import time\n",
    "import datetime\n",
    "from colorama import Fore, Style, init as colorama_init\n",
    "import hashlib\n",
    "colorama_init(autoreset=True)\n",
    "\n",
    "objects_list = df.apply(lambda row: [obj for obj in row if obj is not None], axis=1).tolist()\n",
    "\n",
    "def get_color_from_string(s: str) -> str:\n",
    "    \"\"\"Generate a consistent color from a string using hashing\"\"\"\n",
    "    hash_object = hashlib.md5(s.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    # Use first 6 characters of hash for RGB color\n",
    "    return f\"#{hash_hex[:6]}\"\n",
    "\n",
    "def test_model(model: str, objects_list: list, batch_name: str = \"\") -> tuple:\n",
    "    \"\"\"\n",
    "    For the given model, run tests for each set of objects, printing logs with:\n",
    "       - Timestamp\n",
    "       - Colored status (green for Passed, red for Failed)\n",
    "       - Current success rate (so far)\n",
    "       - Current average test duration (so far)\n",
    "    \n",
    "    Returns a tuple: (model, successes, failures, avg_duration)\n",
    "    \"\"\"\n",
    "    successes = 0\n",
    "    failures = 0\n",
    "    durations = []  # list to record the duration of each test iteration\n",
    "\n",
    "    # Instantiate client and subtasks generator for the model\n",
    "    llm_client = LlmClient(llm_api_key, model, llm_base_url)\n",
    "    subtasks_gen = SubtasksGenerator(llm_client)\n",
    "\n",
    "    # Store failure details for further analysis\n",
    "    failure_cases = []\n",
    "\n",
    "    for i, objects in enumerate(objects_list):\n",
    "        start_time = time.time()\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        try:\n",
    "            subtasks_gen.gen_subtask_paths(objects)\n",
    "            successes += 1\n",
    "            result_text = \"Passed\"\n",
    "            result_color = Fore.GREEN\n",
    "        except Exception:\n",
    "            failures += 1\n",
    "            result_text = \"Failed\"\n",
    "            result_color = Fore.RED\n",
    "            failure_cases.append((objects, str(e)))\n",
    "\n",
    "        iteration_duration = time.time() - start_time\n",
    "        durations.append(iteration_duration)\n",
    "        current_success_rate = (successes / (i + 1)) * 100\n",
    "        current_avg_duration = sum(durations) / len(durations)\n",
    "\n",
    "        print(f\"{timestamp} | [{model}] iteration #{i+1} \"\n",
    "              f\"{result_color}{result_text}{Style.RESET_ALL} | \"\n",
    "              f\"Current success rate: {current_success_rate:.2f}% | \"\n",
    "              f\"Current avg duration: {current_avg_duration:.2f}s\")\n",
    "\n",
    "    avg_duration = sum(durations) / len(durations) if durations else 0\n",
    "\n",
    "    if failures > 0:\n",
    "        print(f\"\\nFailure analysis for {model} ({batch_name}):\")\n",
    "        for i, (objects, error) in enumerate(failure_cases[:5]):\n",
    "            print(f\"Failure #{i+1}: Objects {object}\")\n",
    "            print(f\"Error: {error}\\n\")\n",
    "        if len(failure_cases) > 5:\n",
    "            print(f\"and batch contains {len(failure_cases) - 5} more failures.\")\n",
    "    \n",
    "    return model, successes, failures, avg_duration, batch_name\n",
    "\n",
    "\n",
    "def run_progressive_batch_tests():\n",
    "    all_results = [] # will store tuples: (model, successes, failures, avg_duration, batch_size)\n",
    "    for batch_size in BATCH_SIZES:\n",
    "        print(f\"\\n=== Testing with batch size: {batch_size} ===\\n\")\n",
    "        df = generate_dataset(batch_size)\n",
    "        objects_list = df.apply(lambda row: [obj for obj in row if obj is not None], axis=1).tolist()\n",
    "\n",
    "        batch_results = []\n",
    "        if RUN_PARALLEL:\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=len(AVAILABLE_MODELS)) as executor:\n",
    "                future_to_model = {\n",
    "                    executor.submit(test_model, model, objects_list, f\"Batch-{batch_size}\"): model\n",
    "                    for model in AVAILABLE_MODELS\n",
    "                }\n",
    "                for future in concurrent.futures.as_completed(future_to_model):\n",
    "                    result = future.result()\n",
    "                    batch_results.append(result)\n",
    "        else:\n",
    "            for model in AVAILABLE_MODELS:\n",
    "                result = test_model(model, objects_list, f\"Batch-{batch_size}\")\n",
    "                batch_results.append(result)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Print summary and collect data for graphs\n",
    "# -----------------------------------------------------------------------------\n",
    "        print(f\"\\nSummary for Batch Size {batch_size}:\")\n",
    "        for model, successes, failures, avg_duration, _ in batch_results:\n",
    "            total = successes + failures\n",
    "            success_rate = (successes / total * 100) if total > 0 else 0\n",
    "            status_color = Fore.GREEN if success_rate >= TARGET_ACCURACY else Fore.RED\n",
    "            print(f\"{model}: {successes}/{total} passed ({status_color}{success_rate:.2f}%{Style.RESET_ALL}), \"\n",
    "                  f\"Avg test duration: {avg_duration:.2f}s\")\n",
    "        \n",
    "        all_results.extend(batch_results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Run the progressive batch tests\n",
    "results = run_progressive_batch_tests()\n",
    "\n",
    "# Prepare data for visualization\n",
    "models = list(set([r[0] for r in results]))\n",
    "model_colors = {model: get_color_from_string(model) for model in models}\n",
    "\n",
    "# Process results for batch-wise visualization\n",
    "batch_data = {}\n",
    "for model, successes, failures, avg_duration, batch_name in results:\n",
    "    batch_size = int(batch_name.split('-')[1])\n",
    "    if model not in batch_data:\n",
    "        batch_data[model] = {'batch_sizes': [], 'success_rates': [], 'durations': []}\n",
    "    \n",
    "    total = successes + failures\n",
    "    success_rate = (successes / total * 100) if total > 0 else 0\n",
    "    \n",
    "    batch_data[model]['batch_sizes'].append(batch_size)\n",
    "    batch_data[model]['success_rates'].append(success_rate)\n",
    "    batch_data[model]['durations'].append(avg_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Generation and Visualization\n",
    "- Success Rates by Batch Size compared to target accuracy line (95%)\n",
    "- Average Test Duration by Batch Size\n",
    "- Bar Chart comparing success rates for all models on largest batch size\n",
    "\n",
    "## Scoring system\n",
    "- 80% weight to accuracy, 20% to speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Graph 1: Success Rates per Model and Batch Size\n",
    "# -----------------------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for model in models:\n",
    "    plt.plot(\n",
    "        batch_data[model]['batch_sizes'], \n",
    "        batch_data[model]['success_rates'], \n",
    "        'o-', \n",
    "        color=model_colors[model], \n",
    "        label=model\n",
    "    )\n",
    "\n",
    "plt.axhline(y=TARGET_ACCURACY, color='r', linestyle='--', label=f'Target ({TARGET_ACCURACY}%)')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Success Rate (%)')\n",
    "plt.title('Success Rates by Model and Batch Size')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Graph 2: Average Test Duration per Model and Batch Size\n",
    "# -----------------------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for model in models:\n",
    "    plt.plot(\n",
    "        batch_data[model]['batch_sizes'], \n",
    "        batch_data[model]['durations'], \n",
    "        'o-', \n",
    "        color=model_colors[model], \n",
    "        label=model\n",
    "    )\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Average Test Duration (s)')\n",
    "plt.title('Average Test Duration by Model and Batch Size')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Graph 3: Model Comparison for Largest Batch Size\n",
    "# -----------------------------------------------------------------------------\n",
    "largest_batch = max(BATCH_SIZES)\n",
    "largest_batch_results = [r for r in results if int(r[4].split('-')[1]) == largest_batch]\n",
    "\n",
    "model_names = [r[0] for r in largest_batch_results]\n",
    "success_rates = []\n",
    "avg_durations = []\n",
    "\n",
    "for model, successes, failures, avg_duration, _ in largest_batch_results:\n",
    "    total = successes + failures\n",
    "    success_rate = (successes / total * 100) if total > 0 else 0\n",
    "    success_rates.append(success_rate)\n",
    "    avg_durations.append(avg_duration)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(model_names, success_rates, color=[model_colors[model] for model in model_names])\n",
    "plt.xlabel('LLM Models')\n",
    "plt.ylabel('Success Rate (%)')\n",
    "plt.title(f'Success Rates per LLM Model (Batch Size: {largest_batch})')\n",
    "plt.ylim(0, 100)\n",
    "plt.axhline(y=TARGET_ACCURACY, color='r', linestyle='--', label=f'Target ({TARGET_ACCURACY}%)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for bar, rate in zip(bars, success_rates):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 2, f'{rate:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show all plots\n",
    "plt.show()\n",
    "\n",
    "# Print final summary and recommendations with time consideration\n",
    "print(\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Target Accuracy: {TARGET_ACCURACY}%\")\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_score = 0  # Combined score for accuracy and speed\n",
    "\n",
    "# Define weights for the scoring system\n",
    "ACCURACY_WEIGHT = 0.8  # 80% weight on accuracy\n",
    "SPEED_WEIGHT = 0.2     # 20% weight on speed\n",
    "\n",
    "# Find the fastest model for normalization\n",
    "fastest_time = float('inf')\n",
    "for model in models:\n",
    "    max_batch_idx = batch_data[model]['batch_sizes'].index(max(batch_data[model]['batch_sizes']))\n",
    "    model_time = batch_data[model]['durations'][max_batch_idx]\n",
    "    if model_time < fastest_time:\n",
    "        fastest_time = model_time\n",
    "\n",
    "# Calculate scores and find the best model\n",
    "for model in models:\n",
    "    # Get the max batch size result for this model\n",
    "    max_batch_idx = batch_data[model]['batch_sizes'].index(max(batch_data[model]['batch_sizes']))\n",
    "    final_accuracy = batch_data[model]['success_rates'][max_batch_idx]\n",
    "    final_duration = batch_data[model]['durations'][max_batch_idx]\n",
    "    \n",
    "    # Normalize speed (faster models get higher scores)\n",
    "    speed_score = fastest_time / final_duration if final_duration > 0 else 0\n",
    "    \n",
    "    # Calculate combined score (accuracy + speed)\n",
    "    combined_score = (final_accuracy / 100 * ACCURACY_WEIGHT) + (speed_score * SPEED_WEIGHT)\n",
    "    \n",
    "    status = \" PASSED\" if final_accuracy >= TARGET_ACCURACY else \" FAILED\"\n",
    "    print(f\"{model}: {final_accuracy:.2f}% - {status} | Avg duration: {final_duration:.2f}s | Score: {combined_score:.4f}\")\n",
    "    \n",
    "    if combined_score > best_score:\n",
    "        best_score = combined_score\n",
    "        best_accuracy = final_accuracy\n",
    "        best_model = model\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model} with {best_accuracy:.2f}% accuracy\")\n",
    "print(f\"Combined score (accuracy + speed): {best_score:.4f}\")\n",
    "\n",
    "# Recommendations based on results\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "if best_accuracy >= TARGET_ACCURACY:\n",
    "    print(f\" The {best_model} model meets the target accuracy of {TARGET_ACCURACY}%.\")\n",
    "    print(\"Recommended for production use.\")\n",
    "else:\n",
    "    print(f\" None of the models reached the target accuracy of {TARGET_ACCURACY}%.\")\n",
    "    print(f\"Best model ({best_model}) achieved {best_accuracy:.2f}%.\")\n",
    "    print(\"Recommendations:\")\n",
    "    print(\"1. Try further prompt engineering to improve accuracy\")\n",
    "    print(\"2. Consider fine-tuning the model\")\n",
    "    print(\"3. Explore building a CNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
